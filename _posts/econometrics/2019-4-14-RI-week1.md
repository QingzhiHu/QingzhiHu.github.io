---
layout: post
title: Risk-Insurance Week 1
category: Econometrics
keywords: risk-insurance, week1
---

## Risk Insurance Week 1
- Book: Modern Acturial Risk Theory
- Goal: Ch. 1-3 
- Tutorial: 1.4.6, 2.2.2, 2.4.1, 2.4.12

### Chapter 1: Utility theory and insurance
#### The expected utility model
#### Classes of utility functions
#### Stop-loss reinsurance

### Chapter 2: The individual risk model
#### Mixed distributions and risks
#### Convolution
#### Transforms
#### Approximations
##### Normal approximation
##### Translated gamma approximation 
##### NP approximation
#### Application: optimal reinsurance

### Chapter 3: Collective risk models
#### Compound distributions
##### Convolution formula for a compound cdf 
#### Distributions ofr the number of claims
#### Properties of compound Poisson distirbutions
#### Panjer's recursion
#### Compound distributions and the Fasr Fourier Transform
#### Approximations for compound distributions
#### Individual and collective risk model
#### Loss distributions: properties, estimation, sampling
##### Techniques to generate pseudo-random samples
##### Techniques to compute ML-estimates
##### Poisson claim number distribution



### Tutorial
#### 1.4.6 
Suppose for the random loss X ∼ N(0, 1) an insurance of franchise type is in operation: the amount I(x) paid in case the damage is x equals x when x ≥ d for some d > 0, and zero otherwise. Show that the net premium for this type of insurance is φ(x), where φ(·) is the standard normal density, see Table A. Compare this with the net stop-loss premium with a retention d.

**Sol**
E[I(X)] = $$\int_{d}^{\infty}y\varphi(y) dy=\int_{d}^{\infty}(-\varphi'(y))dy = \varphi(d)$$

If there is payment on the franchise contract, it is d larger than it would be with a stop-loss contract, so $$I(X) = (X-d)_{+}+dI_{X\geq d}$$

Hence $$E[(X-d)_{+}]=\varphi(d)-d[1-\Phi(d)]$$.

$$\frac{d}{dd}E[(X-d)_{+}]=\varphi'(d)-1+\Phi(d)+d\varphi(d)=\Phi(d)-1$$


#### 2.2.2
Throw a true die and let X denote the outcome. Then, toss a coin X times. Let Y denote the number of heads obtained. What are the expected value and the variance of Y ?

**Sol**

$$Y|X = x ~ binomial(x,1/2)$$ so $$E[Y]=E[E[Y|X]]=E[\frac{1}{2}X]=\frac{7}{4}$$

$$Var[Y] = Var[E[Y|X]]+E[Var[Y|X]]=Var[\frac{1}{2}X]+E[\frac{1}{4}X]=\frac{1}{4}\frac{35}{12}+\frac{1}{4}\frac{7}{2}=\frac{77}{48}$$

#### 2.4.1
Determine the cdf of S = X1 + X2 where the Xk are independent and exponential(k) distributed. Do this both by convolution and by calculating the mgf and identifying the corresponding density using the method of partial fractions.

**Sol**

For s > 0, we get using convolution:

$$f_{X_1+X_2}(s)=\int_{-\infty}^{\infty}f_{X_2}(s-x)f_{X_1}(x)dx=\int_{0}^{s}2e^{-2(s-x)}e^{-x}dx=2e^{-2s}\int_{0}^{s}e^x dx = 2(e^{-s}-e^{-2s})$$

on $$(-\infty, 1), m_{X_1+X_2}(t) = \frac{2}{(1-t)(2-t)} = \frac{a}{1-t}+\frac{b}{2-t}$$ for a = 2, b = -2;

so $$m_{X_1+X_2}(t)=2\frac{1}{1-t} - \frac{2}{2-t}$$ = the mgf with the density above.


#### 2.4.12
Show that X and Y are equal in distribution if they have the same support {0,1,...,n} and the same pgf. If X1,X2,... are risks, again with range {0,1,...,n}, such that the pgfs of Xi converge to the pgf of Y for each argument t when i → ∞, verify that also Pr[Xi = x] → Pr[Y = x] for all x.

**Sol**

Their pgfs $$\sum_{x=0}^{n}t^{x}Pr[X=x]$$ are polynomials of degree n. 

We have $$\sum_{x=0}^{n}(Pr[X=x]-Pr[Y=x])t^{x}=0$$ for every t => $$Pr[X=x]-Pr[Y=x]=0$$ for every x

Hence, We have $$\sum_{x=0}^{n}(Pr[X=x]-Pr[Y=x])t^{x} -> 0$$ for every t => $$Pr[X=x]-Pr[Y=x] -> 0$$ for every x







